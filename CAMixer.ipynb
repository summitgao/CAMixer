{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFBnb4v5g0iF"
      },
      "outputs": [],
      "source": [
        "pip install vit-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv8XvXkGhKwR"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/summitgao/CAMixer/main/preclassify.py\n",
        "!unzip \"/content/drive/MyDrive/dataset.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Fl0CNUVbhSr6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import skimage\n",
        "from skimage import io, measure\n",
        "import random\n",
        "import scipy.io as sio\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from preclassify import del2, srad, dicomp, FCM, hcluster\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "from collections import  Counter\n",
        "'''\n",
        "im1_path  = '/content/Chaohu2_1.bmp'\n",
        "im2_path  = '/content/Chaohu2_2.bmp'\n",
        "imgt_path = '/content/Chaohu2_gt.bmp'\n",
        "'''\n",
        "'''\n",
        "im1_path  = '/content/chaohu1/chaohu1_1.bmp'\n",
        "im2_path  = '/content/chaohu1/chaohu1_2.bmp'\n",
        "imgt_path = '/content/chaohu1/result.bmp'\n",
        "'''\n",
        "im1_path  = '/content/dataset/dataset/YellowRiver_1.bmp'\n",
        "im2_path  = '/content/dataset/dataset/YellowRiver_2.bmp'\n",
        "imgt_path = '/content/dataset/dataset/YellowRiver_gt.bmp'\n",
        "# important parameter\n",
        "patch_size = 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0Oe-Fm8khc7x"
      },
      "outputs": [],
      "source": [
        "def image_normalize(data):\n",
        "  import math\n",
        "  _mean = np.mean(data)\n",
        "  _std = np.std(data)\n",
        "  npixel = np.size(data) * 1.0\n",
        "  min_stddev = 1.0 / math.sqrt(npixel)\n",
        "  return (data - _mean) / max(_std, min_stddev)\n",
        "\n",
        "def image_padding(data,r):\n",
        "  if len(data.shape)==3:\n",
        "    data_new=np.lib.pad(data,((r,r),(r,r),(0,0)),'constant',constant_values=0)\n",
        "    return data_new\n",
        "  if len(data.shape)==2:\n",
        "    data_new=np.lib.pad(data,r,'constant',constant_values=0)\n",
        "    return data_new\n",
        "#生成自然数数组并打乱\n",
        "def arr(length):\n",
        "  arr=np.arange(length-1)\n",
        "  #print(arr)\n",
        "  random.shuffle(arr)\n",
        "  #print(arr)\n",
        "  return arr\n",
        "\n",
        "\n",
        "# 在每个像素周围提取 patch ，然后创建成符合 pytorch 处理的格式\n",
        "def createTrainingCubes(X, y, patch_size):\n",
        "  # 给 X 做 padding\n",
        "  margin = int((patch_size - 1) / 2)\n",
        "  zeroPaddedX = image_padding(X, margin)\n",
        "  # 把类别 uncertainty 的像素忽略\n",
        "  ele_num1 = np.sum(y==1)\n",
        "  ele_num2 = np.sum(y==2)\n",
        "  patchesData_1 = np.zeros( (ele_num1, patch_size, patch_size, X.shape[2]) )\n",
        "  patchesLabels_1 = np.zeros(ele_num1)\n",
        "\n",
        "  patchesData_2 = np.zeros((ele_num2, patch_size, patch_size, X.shape[2]))\n",
        "  patchesLabels_2 = np.zeros(ele_num2)\n",
        "\n",
        "  patchIndex_1 = 0\n",
        "  patchIndex_2 = 0\n",
        "  for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "    for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "      # remove uncertainty pixels\n",
        "      if y[r-margin, c-margin] == 1 :\n",
        "        patch_1 = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
        "        patchesData_1[patchIndex_1, :, :, :] = patch_1\n",
        "        patchesLabels_1[patchIndex_1] = y[r-margin, c-margin]\n",
        "        patchIndex_1 = patchIndex_1 + 1\n",
        "      elif y[r-margin, c-margin] == 2 :\n",
        "        patch_2 = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
        "        patchesData_2[patchIndex_2, :, :, :] = patch_2\n",
        "        patchesLabels_2[patchIndex_2] = y[r-margin, c-margin]\n",
        "        patchIndex_2 = patchIndex_2 + 1\n",
        "  patchesLabels_1 = patchesLabels_1-1\n",
        "  patchesLabels_2 = patchesLabels_2-1\n",
        "\n",
        "  #调用arr函数打乱数组\n",
        "  arr_1=arr(len(patchesData_1))\n",
        "  arr_2=arr(len(patchesData_2))\n",
        "\n",
        "  train_len=10000  #设置训练集样本数\n",
        "  pdata=np.zeros((train_len, patch_size, patch_size, X.shape[2]))\n",
        "  plabels = np.zeros(train_len)\n",
        "\n",
        "  for i in range(7000):\n",
        "    pdata[i,:,:,:]=patchesData_1[arr_1[i],:,:,:]\n",
        "    plabels[i]=patchesLabels_1[arr_1[i]]\n",
        "  for j in range(7000,train_len):\n",
        "    pdata[j,:,:,:]=patchesData_2[arr_2[j-7000],:,:,:]\n",
        "    plabels[j]=patchesLabels_2[arr_2[j-7000]]\n",
        "\n",
        "  return pdata, plabels\n",
        "def createTestingCubes(X, patch_size):\n",
        "  # 给 X 做 padding\n",
        "  margin = int((patch_size - 1) / 2)\n",
        "  zeroPaddedX = image_padding(X, margin)\n",
        "  patchesData = np.zeros( (X.shape[0]*X.shape[1], patch_size, patch_size, X.shape[2]) )\n",
        "  patchIndex = 0\n",
        "  for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "    for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "      patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
        "      patchesData[patchIndex, :, :, :] = patch\n",
        "      patchIndex = patchIndex + 1\n",
        "  return patchesData\n",
        "\n",
        "\n",
        "#  Inputs:  gtImg  = ground truth image\n",
        "#           tstImg = change map\n",
        "#  Outputs: FA  = False alarms\n",
        "#           MA  = Missed alarms\n",
        "#           OE  = Overall error\n",
        "#           PCC = Overall accuracy\n",
        "def evaluate(gtImg, tstImg):\n",
        "  gtImg[np.where(gtImg>128)] = 255\n",
        "  gtImg[np.where(gtImg<128)] = 0\n",
        "  tstImg[np.where(tstImg>128)] = 255\n",
        "  tstImg[np.where(tstImg<128)] = 0\n",
        "  [ylen, xlen] = gtImg.shape\n",
        "  FA = 0\n",
        "  MA = 0\n",
        "  label_0 = np.sum(gtImg==0)\n",
        "  label_1 = np.sum(gtImg==255)\n",
        "  print(label_0)\n",
        "  print(label_1)\n",
        "\n",
        "  for j in range(0,ylen):\n",
        "    for i in range(0,xlen):\n",
        "      if gtImg[j,i]==0 and tstImg[j,i]!=0 :\n",
        "        FA = FA+1\n",
        "      if gtImg[j,i]!=0 and tstImg[j,i]==0 :\n",
        "        MA = MA+1\n",
        "\n",
        "  OE = FA+MA\n",
        "  PCC = 1-OE/(ylen*xlen)\n",
        "  PRE=((label_1+FA-MA)*label_1+(label_0+MA-FA)*label_0)/((ylen*xlen)*(ylen*xlen))\n",
        "  KC=(PCC-PRE)/(1-PRE)\n",
        "  print(' Change detection results ==>')\n",
        "  print(' ... ... FP:  ', FA)\n",
        "  print(' ... ... FN:  ', MA)\n",
        "  print(' ... ... OE:  ', OE)\n",
        "  print(' ... ... PCC: ', format(PCC*100, '.2f'))\n",
        "  print(' ... ... KC: ', format(KC*100, '.2f'))\n",
        "\n",
        "def postprocess1(res):\n",
        "  res_new = res\n",
        "  res = measure.label(res, connectivity=2)\n",
        "  #print(res)\n",
        "  num = res.max()\n",
        "  #print(num)\n",
        "  for i in range(1, num+1):\n",
        "    idy, idx = np.where(res==i)\n",
        "    if len(idy) <= 20:\n",
        "      res_new[idy, idx] = 0\n",
        "  return res_new\n",
        "def postprocess(res):\n",
        "  res_new = res\n",
        "  res = measure.label(res, connectivity=2)\n",
        "  #print(res)\n",
        "  num = res.max()\n",
        "  #print(num)\n",
        "  for i in range(1, num+1):\n",
        "    idy, idx = np.where(res==i)\n",
        "    if len(idy) <= 20:\n",
        "      res_new[idy, idx] = 0.5\n",
        "  return res_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6HUsx3WhfpH",
        "outputId": "e6b5977b-489b-4a35-f772-eb8e352d2d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... ... 1st round clustering ... ...\n",
            "... ... 2nd round clustering ... ...\n",
            "... ... hiearchical clustering finished !!!\n",
            "... x train shape:  (10000, 3, 9, 9)\n",
            "... y train shape:  (10000,)\n",
            "... x test shape:  (74273, 3, 9, 9)\n"
          ]
        }
      ],
      "source": [
        "# read image, and then tranform to float32\n",
        "\n",
        "im1 = io.imread(im1_path).astype(np.float32)\n",
        "im2 = io.imread(im2_path).astype(np.float32)\n",
        "'''\n",
        "print(im1.shape)\n",
        "print(im2.shape)\n",
        "print(type(im1))\n",
        "\n",
        "'''\n",
        "im_gt = io.imread(imgt_path).astype(np.float32)\n",
        "\n",
        "'''\n",
        "im_gt = Image.open(imgt_path)\n",
        "im_gt = np.array(im_gt)\n",
        "np.unique(im_gt)\n",
        "\n",
        "'''\n",
        "im_di = dicomp(im1, im2)\n",
        "ylen, xlen = im_di.shape\n",
        "pix_vec = im_di.reshape([ylen*xlen, 1])\n",
        "\n",
        "# hiearchical FCM clustering\n",
        "# in the preclassification map,\n",
        "# pixels with high probability to be unchanged are labeled as 1\n",
        "# pixels with high probability to be changed are labeled as 2\n",
        "# pixels with uncertainty are labeled as 1.5\n",
        "preclassify_lab = hcluster(pix_vec, im_di)\n",
        "#preclassify_lab = postprocess(preclassify_lab - 1) + 1\n",
        "print('... ... hiearchical clustering finished !!!')\n",
        "\n",
        "\n",
        "mdata = np.zeros([im1.shape[0], im1.shape[1], 3], dtype=np.float32)\n",
        "mdata[:,:,0] = im1\n",
        "mdata[:,:,1] = im2\n",
        "mdata[:,:,2] = im_di\n",
        "mlabel = preclassify_lab\n",
        "\n",
        "x_train, y_train = createTrainingCubes(mdata, mlabel, patch_size)\n",
        "x_train = x_train.transpose(0, 3, 1, 2)\n",
        "print('... x train shape: ', x_train.shape)\n",
        "print('... y train shape: ', y_train.shape)\n",
        "\n",
        "\n",
        "x_test = createTestingCubes(mdata, patch_size)\n",
        "x_test = x_test.transpose(0, 3, 1, 2)\n",
        "print('... x test shape: ', x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fq-QjHIihmu2"
      },
      "outputs": [],
      "source": [
        "\"\"\" Training dataset\"\"\"\n",
        "class TrainDS(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    self.len = x_train.shape[0]\n",
        "    self.x_data = torch.FloatTensor(x_train)\n",
        "    self.y_data = torch.LongTensor(y_train)\n",
        "  def __getitem__(self, index):\n",
        "    # 根据索引返回数据和对应的标签\n",
        "\n",
        "    #x=torch.FloatTensor(data_rotate(self.x_data[index].cpu().numpy()))\n",
        "    #y=torch.FloatTensor(gasuss_noise(self.y_data[index]))\n",
        "    #x=torch.FloatTensor(datarotate(self.x_data[index]))\n",
        "    #return x,self.y_data[index]\n",
        "    return self.x_data[index], self.y_data[index]\n",
        "  def __len__(self):\n",
        "    # 返回文件数据的数目\n",
        "    return self.len\n",
        "\n",
        "# 创建 trainloader 和 testloader\n",
        "trainset = TrainDS()\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=128, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K2YRz6Lvg9YP"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import glob\n",
        "from itertools import chain\n",
        "import os\n",
        "import random\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "# Training settings\n",
        "epochs = 10\n",
        "lr = 3e-5\n",
        "gamma = 0.7\n",
        "seed = 42\n",
        "def seed_everything(seed):\n",
        "  random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything(seed)\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "def pair(t):\n",
        "  return t if isinstance(t, tuple) else (t, t)\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
        "    super().__init__()\n",
        "    inner_dim = dim_head *  heads\n",
        "    project_out = not (heads == 1 and dim_head == dim)\n",
        "    self.heads = heads\n",
        "    self.scale = dim_head ** -0.5\n",
        "    self.attend = nn.Softmax(dim = -1)\n",
        "    self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "\n",
        "    self.to_out = nn.Sequential(\n",
        "        nn.Linear(inner_dim, dim),\n",
        "        nn.Dropout(dropout)\n",
        "    ) if project_out else nn.Identity()\n",
        "  def forward(self, x):\n",
        "    qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
        "    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
        "    dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "    attn = self.attend(dots)\n",
        "    out = torch.matmul(attn, v)\n",
        "    out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "    return self.to_out(out)\n",
        "\n",
        "class ViT(nn.Module):\n",
        "  def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
        "    super().__init__()\n",
        "    image_height, image_width = pair(image_size)\n",
        "    patch_height, patch_width = pair(patch_size)\n",
        "    assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
        "    num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
        "    patch_dim = channels * patch_height * patch_width\n",
        "    assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "    self.to_patch_embedding = nn.Sequential(\n",
        "        Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
        "        nn.Linear(patch_dim, dim),\n",
        "    )\n",
        "    self.transformer = Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)\n",
        "    self.reshape = Rearrange('b (h w) (p1 p2 c) -> b c (h p1) (w p2)', p1 = patch_height, p2 = patch_width, h = image_height // patch_height)\n",
        "\n",
        "  def forward(self, img):\n",
        "    x = self.to_patch_embedding(img)\n",
        "    x = self.transformer(x)\n",
        "    #print(x.shape)\n",
        "    x = self.reshape(x)\n",
        "    #print(x.shape)\n",
        "    return x\n",
        "vit = ViT(\n",
        "  image_size = 9,\n",
        "  patch_size = 3,\n",
        "  num_classes = 2,\n",
        "  dim = 27,\n",
        "  depth = 6,\n",
        "  heads = 4,\n",
        "  mlp_dim = 32,\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "vEVYb7pvgP_m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shift(y, n = 6):\n",
        "  B, C, H, W = y.shape\n",
        "  num = C // n\n",
        "  out = torch.zeros_like(y)\n",
        "  out[:, num * 0:num * 1, 1:, :] = y[:, num * 0:num * 1, :-1, :]  # shift down\n",
        "  out[:, num * 1:num * 2, :-1, :] = y[:, num * 1:num * 2, 1:, :]  # shift up\n",
        "  out[:, num * 2:num * 3, :, :-1] = y[:, num * 2:num * 3, :, 1:]  # shift left\n",
        "  out[:, num * 3:num * 4, :, 1:] = y[:, num * 3:num * 4, :, :-1]  # shift right\n",
        "  out[:, num * 4:, :, :] = y[:, num * 4:, :, :]  # no shift\n",
        "  return out\n",
        "class CSC(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CSC, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,12,1,1)\n",
        "    self.shift = shift\n",
        "    self.conv2 = nn.Conv2d(12,3,1,1)\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = shift(x)\n",
        "    x = self.conv2(x)\n",
        "    return x\n",
        "class SGU(nn.Module):\n",
        "  def __init__(self, dim = 3):\n",
        "    super(SGU, self).__init__()\n",
        "    self.catConv =  nn.Conv2d(6, 3, kernel_size=1)\n",
        "    self.norm1 = nn.LayerNorm([3, patch_size, patch_size])\n",
        "    self.conv = nn.Conv2d(3,8,1,1)\n",
        "    self.project_in = nn.Conv2d(3, 16, kernel_size=1)\n",
        "    self.dwconv = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1, groups=16, bias=False)\n",
        "    self.project_out = nn.Conv2d(8, 3, kernel_size=1)\n",
        "  def forward(self, x):\n",
        "    catOut = self.catConv(x)\n",
        "    x = catOut\n",
        "    x = self.norm1(x)\n",
        "    x = self.project_in(x)\n",
        "    x1, x2 = self.dwconv(x).chunk(2, dim=1)\n",
        "    x = F.gelu(x1) * x2\n",
        "    catOut = self.conv(catOut)\n",
        "    x = x + catOut\n",
        "    x = self.project_out(x)\n",
        "    return x\n",
        "class CAMixer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CAMixer, self).__init__()\n",
        "    self.vit = vit\n",
        "    self.csc = CSC()\n",
        "    self.sgu = SGU()\n",
        "    self.linear1=nn.Linear(patch_size * patch_size * 3, 20)\n",
        "    self.linear2=nn.Linear(20, 2)\n",
        "  def forward(self, img):\n",
        "    in_x = img.reshape(img.shape[0],-1)\n",
        "    vitOut = self.vit(img)\n",
        "    vitout = vitOut.reshape(vitOut.shape[0],1,-1)\n",
        "    cscOut = self.csc(img)\n",
        "    cscout = cscOut.reshape(cscOut.shape[0],1,-1)\n",
        "    catOut = torch.cat((vitOut, cscOut), 1)\n",
        "    catout = catOut.reshape(catOut.shape[0],1,-1)\n",
        "    x = self.sgu(catOut)\n",
        "    sguout = x.reshape(x.shape[0],1,-1)\n",
        "    out1 = x.view(x.size(0), -1)     #128 1470\n",
        "    out1 = self.linear1(out1)\n",
        "    out1 = self.linear2(out1)\n",
        "    return in_x, vitout, cscout, catout, sguout, out1"
      ],
      "metadata": {
        "id": "TkDTZvl2g1Rp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "#criterion = SCELoss(0.2,1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer\n",
        "model = CAMixer().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "# scheduler\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
      ],
      "metadata": {
        "id": "HWb7FVGLg_94"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = np.zeros((ylen, xlen))\n",
        "for epoch in range(25):\n",
        "  epoch_loss = 0\n",
        "  epoch_accuracy = 0\n",
        "  for data, label in tqdm(train_loader):\n",
        "    data = data.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    in_x, vitout, cscout, catout, sguout, output = model(data)\n",
        "    loss = criterion(output, label)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    acc = (output.argmax(dim=1) == label).float().mean()\n",
        "    epoch_accuracy += acc / len(train_loader)\n",
        "    epoch_loss += loss / len(train_loader)\n",
        "  print(\n",
        "      f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f}\\n\"\n",
        "  )"
      ],
      "metadata": {
        "id": "pO6GuBRwhCHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "geZXeuFYMwf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "istrain=False\n",
        "model.eval()\n",
        "outputs = np.zeros((ylen, xlen))\n",
        "for i in range(ylen):\n",
        "  for j in range(xlen):\n",
        "    if preclassify_lab[i, j] != 1.5 :\n",
        "      outputs[i, j] = preclassify_lab[i, j]\n",
        "    else:\n",
        "      img_patch = x_test[i*xlen+j, :, :, :]\n",
        "      img_patch = img_patch.reshape(1, img_patch.shape[0], img_patch.shape[1], img_patch.shape[2])\n",
        "      img_patch = torch.FloatTensor(img_patch).to(device)\n",
        "      #img_patch = torch.FloatTensor(img_patch)\n",
        "      in_x, vitout, cscout, catout, sguout, prediction = model(img_patch)\n",
        "      prediction = np.argmax(prediction.detach().cpu().numpy(), axis=1)\n",
        "      outputs[i, j] = prediction+1\n",
        "  if (i+1) % 50 == 0:\n",
        "    print('... ... row', i+1, ' handling ... ...')\n",
        "\n",
        "outputs = outputs-1\n",
        "\n",
        "plt.imshow(outputs, 'gray')\n",
        "\n",
        "\n",
        "res = outputs*255\n",
        "res = postprocess(res)\n",
        "evaluate(im_gt, res)\n",
        "plt.imshow(res, 'gray')"
      ],
      "metadata": {
        "id": "3NNwWrxBhG_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MPqpT49Y3Ya",
        "outputId": "aa31b43b-8dce-4a5a-c45f-5d39b89cafab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
